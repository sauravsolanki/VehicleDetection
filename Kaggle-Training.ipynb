{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-27T16:33:28.62828Z","iopub.execute_input":"2021-08-27T16:33:28.62874Z","iopub.status.idle":"2021-08-27T16:33:28.677028Z","shell.execute_reply.started":"2021-08-27T16:33:28.628677Z","shell.execute_reply":"2021-08-27T16:33:28.67591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -U scikit-image==0.16.2\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:33:28.686172Z","iopub.execute_input":"2021-08-27T16:33:28.686697Z","iopub.status.idle":"2021-08-27T16:33:28.692314Z","shell.execute_reply.started":"2021-08-27T16:33:28.686654Z","shell.execute_reply":"2021-08-27T16:33:28.690627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import skimage\nskimage.__version__","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:33:28.69457Z","iopub.execute_input":"2021-08-27T16:33:28.695262Z","iopub.status.idle":"2021-08-27T16:33:28.716259Z","shell.execute_reply.started":"2021-08-27T16:33:28.695196Z","shell.execute_reply":"2021-08-27T16:33:28.714948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# restructure the code for maskrcnn\n!cp -r \"/kaggle/input/object-detection-tf2/object-detection-master\" \"/kaggle/working/\"\n!cp \"/kaggle/input/maskrcnnmodel/mask_rcnn_coco.h5\" \"/kaggle/working/object-detection-master/Mask_RCNN\"\n!cp -r \"/kaggle/input/kangaroo-and-indian-busy-road/dataset\" \"/kaggle/working/object-detection-master/Mask_RCNN\"","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:33:30.644433Z","iopub.execute_input":"2021-08-27T16:33:30.644833Z","iopub.status.idle":"2021-08-27T16:33:57.349348Z","shell.execute_reply.started":"2021-08-27T16:33:30.644785Z","shell.execute_reply":"2021-08-27T16:33:57.3479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:33:57.353912Z","iopub.execute_input":"2021-08-27T16:33:57.35426Z","iopub.status.idle":"2021-08-27T16:33:57.402564Z","shell.execute_reply.started":"2021-08-27T16:33:57.354225Z","shell.execute_reply":"2021-08-27T16:33:57.401518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.insert(0,\"/kaggle/working/object-detection-master/Mask_RCNN\")","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:33:57.404916Z","iopub.execute_input":"2021-08-27T16:33:57.405425Z","iopub.status.idle":"2021-08-27T16:33:57.43836Z","shell.execute_reply.started":"2021-08-27T16:33:57.405379Z","shell.execute_reply":"2021-08-27T16:33:57.437055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/object-detection-master/Mask_RCNN","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:33:57.440644Z","iopub.execute_input":"2021-08-27T16:33:57.441224Z","iopub.status.idle":"2021-08-27T16:33:57.479271Z","shell.execute_reply.started":"2021-08-27T16:33:57.441176Z","shell.execute_reply":"2021-08-27T16:33:57.477925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python setup.py install","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:33:57.481119Z","iopub.execute_input":"2021-08-27T16:33:57.481992Z","iopub.status.idle":"2021-08-27T16:34:00.715046Z","shell.execute_reply.started":"2021-08-27T16:33:57.48194Z","shell.execute_reply":"2021-08-27T16:34:00.713702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split into train and test set\nfrom os import listdir\nfrom xml.etree import ElementTree\nfrom numpy import zeros\nfrom numpy import asarray\nfrom mrcnn.utils import Dataset\nfrom matplotlib import pyplot\nfrom mrcnn.visualize import display_instances\nfrom mrcnn.utils import extract_bboxes\nimport os\nimport cv2\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image,ImageDraw\nfrom mrcnn.utils import extract_bboxes\nfrom mrcnn.model import load_image_gt\nfrom mrcnn.model import mold_image\nfrom mrcnn.utils import compute_ap\nfrom matplotlib.patches import Rectangle\n","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:00.718904Z","iopub.execute_input":"2021-08-27T16:34:00.719303Z","iopub.status.idle":"2021-08-27T16:34:08.1302Z","shell.execute_reply.started":"2021-08-27T16:34:00.719269Z","shell.execute_reply":"2021-08-27T16:34:08.129055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# class that defines and loads the kangaroo dataset\nclass MathikereDataset(Dataset):\n    \n    # load the dataset definitions\n    def load_dataset(self, dataset_dir, is_train=True):\n        # define one class\n        self.add_class(\"dataset\", 1, \"person\")\n        self.add_class(\"dataset\", 2, \"twowheeler\")\n        self.add_class(\"dataset\", 3, \"fourwheeler\")\n        \n        \n        # define data locations\n        images_dir = dataset_dir + '/images/'\n        annotations_dir = dataset_dir + '/annotations/'\n        \n        # find all images\n        for filename in listdir(images_dir):\n            # extract image id\n            image_id = filename[:-4]\n            \n            image_No = image_id.replace(\"frame_\",\"\")\n                \n            # skip all images after 150 if we are building the train set\n            if is_train and int(image_No) <= 150:\n                continue\n                \n            # skip all images before 150 if we are building the test/val set\n            if not is_train and int(image_No) >= 150:\n                continue\n                \n            img_path = images_dir + filename\n            ann_path = annotations_dir + image_id + '.xml'\n            \n            # add to dataset\n            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n\n    # extract bounding boxes from an annotation file\n    def extract_boxes(self, filename):\n        # load and parse the file\n        tree = ElementTree.parse(filename)\n        # get the root of the document\n        root = tree.getroot()\n        # extract each bounding box\n        boxes = list()\n        for box in root.findall('.//bndbox'):\n            xmin = int(box.find('xmin').text)\n            ymin = int(box.find('ymin').text)\n            xmax = int(box.find('xmax').text)\n            ymax = int(box.find('ymax').text)\n            coors = [xmin, ymin, xmax, ymax]\n            boxes.append(coors)\n        # extract image dimensions\n        width = int(root.find('.//size/width').text)\n        height = int(root.find('.//size/height').text)\n        return boxes, width, height\n\n    # load the masks for an image\n    def load_mask(self, image_id):\n        # get details of image\n        info = self.image_info[image_id]\n        # define box file location\n        path = info['annotation']\n        # load XML\n        _,masks,_,class_ids, _, _ = self.extract_helper(path)            \n        return masks, asarray(class_ids, dtype='int32')\n\n    # load an image reference\n    def image_reference(self, image_id):\n        info = self.image_info[image_id]\n        return info['path']\n    \n\n    # extract bounding boxes from an annotation file\n    def extract_helper(self,filename):\n\n        # labels\n\n        # load and parse the file\n#         path = \"/home/saurav/Documents/Learning/KangarooDetection/Mask_RCNN/dataset/mathikere\"\n        tree = ElementTree.parse(filename)\n        # get the root of the document\n        root = tree.getroot()\n\n        width = int(root.find('.//imagesize/nrows').text)\n        height = int(root.find('.//imagesize/ncols').text)\n\n#         print(width,height)\n\n        boxes = list()\n        names = list()\n        img_polygons = list()\n        masks = list()\n        class_ids = list()\n\n        for member in root.findall('object'):\n            polygons = list()\n            name = member.find(\"name\").text\n            class_id = self.class_names.index(name)\n\n            for polypoints in member.findall('.//polygon/pt'):            \n                x = int(float(polypoints.find(\"x\").text))\n                y = int(float(polypoints.find(\"y\").text))\n                polygons.append((x,y))\n\n            # # polygons to bbox\n            x,y,w,h = cv2.boundingRect(np.array(polygons))\n            boxes.append((x,y,x+w,y+h))\n\n            # polypoints to masks\n            img = Image.new('L', (height,width), 0)\n            ImageDraw.Draw(img).polygon(polygons, outline=1, fill=1)\n            mask = np.array(img)\n\n\n            # Add to list\n            img_polygons.append(polygons)\n            names.append(name)\n            masks.append(mask)\n            class_ids.append(class_id)\n            \n        masks = np.transpose(np.array(masks), (1, 2,0))\n\n\n        return np.array(img_polygons),np.array(masks), np.array(boxes), np.array(class_ids), width, height\n\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:08.131746Z","iopub.execute_input":"2021-08-27T16:34:08.132251Z","iopub.status.idle":"2021-08-27T16:34:08.218771Z","shell.execute_reply.started":"2021-08-27T16:34:08.132197Z","shell.execute_reply":"2021-08-27T16:34:08.217414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train set\ntrain_set = MathikereDataset()\ntrain_set.load_dataset('./dataset/mathikere', is_train=True)\ntrain_set.prepare()\n# load an image\nimage_id = 0\nimage = train_set.load_image(image_id)\nprint(image.shape)\n# load image mask\nmask, class_ids = train_set.load_mask(image_id)\nprint(mask.shape)\n# plot image\npyplot.imshow(image)\n# plot mask\npyplot.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:08.222953Z","iopub.execute_input":"2021-08-27T16:34:08.22347Z","iopub.status.idle":"2021-08-27T16:34:08.992306Z","shell.execute_reply.started":"2021-08-27T16:34:08.223424Z","shell.execute_reply":"2021-08-27T16:34:08.991051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train set\ntrain_set = MathikereDataset()\ntrain_set.load_dataset('./dataset/mathikere', is_train=True)\ntrain_set.prepare()\nprint('Train: %d' % len(train_set.image_ids))\n\n# test/val set\ntest_set = MathikereDataset()\ntest_set.load_dataset('./dataset/mathikere', is_train=False)\ntest_set.prepare()\nprint('Test: %d' % len(test_set.image_ids))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:08.994694Z","iopub.execute_input":"2021-08-27T16:34:08.995245Z","iopub.status.idle":"2021-08-27T16:34:09.075489Z","shell.execute_reply.started":"2021-08-27T16:34:08.995191Z","shell.execute_reply":"2021-08-27T16:34:09.073759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) ","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:09.077545Z","iopub.execute_input":"2021-08-27T16:34:09.078224Z","iopub.status.idle":"2021-08-27T16:34:09.149439Z","shell.execute_reply.started":"2021-08-27T16:34:09.078176Z","shell.execute_reply":"2021-08-27T16:34:09.148181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train set\ntrain_set = MathikereDataset()\ntrain_set.load_dataset('./dataset/mathikere', is_train=True)\ntrain_set.prepare()\n# load an image\nimage_id = 0\nimage = train_set.load_image(image_id)\nprint(image.shape)\n# load image mask\nmask, class_ids = train_set.load_mask(image_id)\nprint(mask.shape)\n# plot image\n# pyplot.imshow(image)\n# plot mask\npyplot.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)\npyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:09.151273Z","iopub.execute_input":"2021-08-27T16:34:09.151755Z","iopub.status.idle":"2021-08-27T16:34:09.637484Z","shell.execute_reply.started":"2021-08-27T16:34:09.151707Z","shell.execute_reply":"2021-08-27T16:34:09.636212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_many():\n    # plot first few images\n    for i in range(9):\n        # define subplot\n        pyplot.subplot(330 + 1 + i)\n        # plot raw pixel data\n        image = train_set.load_image(i)\n        pyplot.imshow(image)\n        # plot all masks\n        mask, _ = train_set.load_mask(i)\n        for j in range(mask.shape[2]):\n            pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n    # show the figure\n    pyplot.show()\n    \nshow_many()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:09.638906Z","iopub.execute_input":"2021-08-27T16:34:09.639574Z","iopub.status.idle":"2021-08-27T16:34:26.396165Z","shell.execute_reply.started":"2021-08-27T16:34:09.639529Z","shell.execute_reply":"2021-08-27T16:34:26.395064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using mrcnn visualise\n# define image id\nimage_id = 1\n# load the image\nimage = train_set.load_image(image_id)\n# load the masks and the class ids\nmask, class_ids = train_set.load_mask(image_id)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:26.397681Z","iopub.execute_input":"2021-08-27T16:34:26.398145Z","iopub.status.idle":"2021-08-27T16:34:26.536508Z","shell.execute_reply.started":"2021-08-27T16:34:26.398102Z","shell.execute_reply":"2021-08-27T16:34:26.535354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract bounding boxes from the masks\nbbox = extract_bboxes(mask)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:26.538186Z","iopub.execute_input":"2021-08-27T16:34:26.538615Z","iopub.status.idle":"2021-08-27T16:34:26.615094Z","shell.execute_reply.started":"2021-08-27T16:34:26.538572Z","shell.execute_reply":"2021-08-27T16:34:26.613996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display image with masks and bounding boxes\ndisplay_instances(image, bbox, mask, class_ids, train_set.class_names)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:26.616978Z","iopub.execute_input":"2021-08-27T16:34:26.617484Z","iopub.status.idle":"2021-08-27T16:34:28.017095Z","shell.execute_reply.started":"2021-08-27T16:34:26.617439Z","shell.execute_reply":"2021-08-27T16:34:28.015761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from mrcnn.config import Config\nfrom mrcnn.model import MaskRCNN","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:28.018905Z","iopub.execute_input":"2021-08-27T16:34:28.019335Z","iopub.status.idle":"2021-08-27T16:34:28.101817Z","shell.execute_reply.started":"2021-08-27T16:34:28.019293Z","shell.execute_reply":"2021-08-27T16:34:28.10073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define a configuration for the model\nclass MathikereTrainConfig(Config):\n    # define the name of the configuration\n    NAME = \"kangaroo_cfg\"\n    # number of classes (background + no of class)\n    NUM_CLASSES = 1 + 3\n    \n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n    \n    # number of training steps per epoch\n    STEPS_PER_EPOCH = 131","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:28.105379Z","iopub.execute_input":"2021-08-27T16:34:28.105753Z","iopub.status.idle":"2021-08-27T16:34:28.176245Z","shell.execute_reply.started":"2021-08-27T16:34:28.105721Z","shell.execute_reply":"2021-08-27T16:34:28.175084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train set\ntrain_set = MathikereDataset()\ntrain_set.load_dataset('./dataset/mathikere', is_train=True)\ntrain_set.prepare()\nprint('Train: %d' % len(train_set.image_ids))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:28.177938Z","iopub.execute_input":"2021-08-27T16:34:28.17849Z","iopub.status.idle":"2021-08-27T16:34:28.254236Z","shell.execute_reply.started":"2021-08-27T16:34:28.178441Z","shell.execute_reply":"2021-08-27T16:34:28.252431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test/val set\ntest_set = MathikereDataset()\ntest_set.load_dataset('./dataset/mathikere', is_train=False)\ntest_set.prepare()\nprint('Test: %d' % len(test_set.image_ids))","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:28.256338Z","iopub.execute_input":"2021-08-27T16:34:28.256856Z","iopub.status.idle":"2021-08-27T16:34:28.328426Z","shell.execute_reply.started":"2021-08-27T16:34:28.256781Z","shell.execute_reply":"2021-08-27T16:34:28.326899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prepare config\nconfig = MathikereTrainConfig()\nconfig.display()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:28.330674Z","iopub.execute_input":"2021-08-27T16:34:28.331538Z","iopub.status.idle":"2021-08-27T16:34:28.416656Z","shell.execute_reply.started":"2021-08-27T16:34:28.331491Z","shell.execute_reply":"2021-08-27T16:34:28.415495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the model\nmodel = MaskRCNN(mode='training', model_dir='./', config=config)\n# load weights (mscoco) and exclude the output layers\nmodel.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:34:28.418377Z","iopub.execute_input":"2021-08-27T16:34:28.418829Z","iopub.status.idle":"2021-08-27T16:34:46.18593Z","shell.execute_reply.started":"2021-08-27T16:34:28.418784Z","shell.execute_reply":"2021-08-27T16:34:46.184557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train weights (output layers or 'heads')\nmodel.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:35:30.707764Z","iopub.execute_input":"2021-08-27T16:35:30.708312Z","iopub.status.idle":"2021-08-27T16:56:02.386654Z","shell.execute_reply.started":"2021-08-27T16:35:30.708266Z","shell.execute_reply":"2021-08-27T16:56:02.384687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the prediction configuration\nclass PredictionConfig(Config):\n    # define the name of the configuration\n    NAME = \"kangaroo_cfg\"\n    # number of classes (background + kangaroo)\n    NUM_CLASSES = 1 + 3\n    # simplify GPU config\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:56:37.614284Z","iopub.execute_input":"2021-08-27T16:56:37.614947Z","iopub.status.idle":"2021-08-27T16:56:38.27709Z","shell.execute_reply.started":"2021-08-27T16:56:37.614884Z","shell.execute_reply":"2021-08-27T16:56:38.275684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculate the mAP for a model on a given dataset\ndef evaluate_model(dataset, model, cfg):\n    APs = list()\n    for image_id in dataset.image_ids:\n        # load image, bounding boxes and masks for the image id\n        image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id)\n        # convert pixel values (e.g. center)\n        scaled_image = mold_image(image, cfg)\n        # convert image into one sample\n        sample = np.expand_dims(scaled_image, 0)\n        # make prediction\n        yhat = model.detect(sample, verbose=0)\n        # extract results for first sample\n        r = yhat[0]\n        # calculate statistics, including AP\n        AP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n        # store\n        APs.append(AP)\n    # calculate the mean AP across all images\n    mAP = mean(APs)\n    return mAP\n\n\n# create config\ncfg = PredictionConfig()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T16:56:39.371914Z","iopub.execute_input":"2021-08-27T16:56:39.37256Z","iopub.status.idle":"2021-08-27T16:56:39.770197Z","shell.execute_reply.started":"2021-08-27T16:56:39.372509Z","shell.execute_reply":"2021-08-27T16:56:39.767882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l -1t","metadata":{"execution":{"iopub.status.busy":"2021-08-27T17:01:56.667612Z","iopub.execute_input":"2021-08-27T17:01:56.668008Z","iopub.status.idle":"2021-08-27T17:01:57.618856Z","shell.execute_reply.started":"2021-08-27T17:01:56.667973Z","shell.execute_reply":"2021-08-27T17:01:57.617671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the model\nmodel = MaskRCNN(mode='inference', model_dir='./', config=cfg)\n\n# load model weights\n# mask_rcnn_kangaroo_cfg_{epoch:04d}.h5\nmodel.load_weights('kangaroo_cfg20210827T1634/mask_rcnn_kangaroo_cfg_0005.h5', by_name=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T17:04:03.87996Z","iopub.execute_input":"2021-08-27T17:04:03.880431Z","iopub.status.idle":"2021-08-27T17:04:21.224616Z","shell.execute_reply.started":"2021-08-27T17:04:03.880397Z","shell.execute_reply":"2021-08-27T17:04:21.223436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate model on training dataset\n# FAILED: ValueError: shapes (100,1048576) and (3136,22) not aligned: 1048576 (dim 1) != 3136 (dim 0)\ntrain_mAP = evaluate_model(train_set, model, cfg)\nprint(\"Train mAP: %.3f\" % train_mAP)\n# evaluate model on test dataset\ntest_mAP = evaluate_model(test_set, model, cfg)\nprint(\"Test mAP: %.3f\" % test_mAP)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot a number of photos with ground truth and predictions\ndef plot_actual_vs_predicted(dataset, model, cfg, n_images=5):\n    # load image and mask\n    for i in range(n_images):\n        # load the image and mask\n        image = dataset.load_image(i)\n        mask, _ = dataset.load_mask(i)\n        # convert pixel values (e.g. center)\n        scaled_image = mold_image(image, cfg)\n        # convert image into one sample\n        sample = np.expand_dims(scaled_image, 0)\n        # make prediction\n        yhat = model.detect(sample, verbose=0)[0]\n        # define subplot\n        pyplot.subplot(n_images, 2, i*2+1)\n        # plot raw pixel data\n        pyplot.imshow(image)\n        pyplot.title('Actual')\n        # plot masks\n        for j in range(mask.shape[2]):\n            pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n        # get the context for drawing boxes\n        pyplot.subplot(n_images, 2, i*2+2)\n        # plot raw pixel data\n        pyplot.imshow(image)\n        pyplot.title('Predicted')\n        ax = pyplot.gca()\n        # plot each box\n        for box in yhat['rois']:\n            # get coordinates\n            y1, x1, y2, x2 = box\n            # calculate width and height of the box\n            width, height = x2 - x1, y2 - y1\n            # create the shape\n            rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n            # draw the box\n            ax.add_patch(rect)\n    # show the figure\n    pyplot.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-27T17:05:04.428075Z","iopub.execute_input":"2021-08-27T17:05:04.42856Z","iopub.status.idle":"2021-08-27T17:05:04.507431Z","shell.execute_reply.started":"2021-08-27T17:05:04.428516Z","shell.execute_reply":"2021-08-27T17:05:04.506251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot predictions for train dataset\nplot_actual_vs_predicted(train_set, model, cfg)\n\n# plot predictions for test dataset\nplot_actual_vs_predicted(test_set, model, cfg)","metadata":{"execution":{"iopub.status.busy":"2021-08-27T17:05:05.205942Z","iopub.execute_input":"2021-08-27T17:05:05.206396Z","iopub.status.idle":"2021-08-27T17:05:29.652956Z","shell.execute_reply.started":"2021-08-27T17:05:05.206364Z","shell.execute_reply":"2021-08-27T17:05:29.651935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip ../model.zip kangaroo_cfg20210827T1634/mask_rcnn_kangaroo_cfg_0005.h5","metadata":{"execution":{"iopub.status.busy":"2021-08-27T17:09:28.698274Z","iopub.execute_input":"2021-08-27T17:09:28.698672Z","iopub.status.idle":"2021-08-27T17:09:44.50967Z","shell.execute_reply.started":"2021-08-27T17:09:28.698639Z","shell.execute_reply":"2021-08-27T17:09:44.508404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"./object-detection-master/model.zip\"> Download File </a>","metadata":{"execution":{"iopub.status.busy":"2021-08-27T17:14:27.152080Z","iopub.execute_input":"2021-08-27T17:14:27.152552Z","iopub.status.idle":"2021-08-27T17:14:27.225453Z","shell.execute_reply.started":"2021-08-27T17:14:27.152504Z","shell.execute_reply":"2021-08-27T17:14:27.223238Z"}}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}